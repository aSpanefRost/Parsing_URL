{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from fake_useragent import UserAgent\n",
    "import urllib\n",
    "import time\n",
    "import traceback\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Data set\n",
    "df=pd.read_csv(\"combo.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Recipe ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5 spice vegetable fried rice</td>\n",
       "      <td>TARLA_DALAL</td>\n",
       "      <td>Indian Subcontinent</td>\n",
       "      <td>capsicum ,pepper bell ,soy sauce ,sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>aachar aaloo</td>\n",
       "      <td>TARLA_DALAL</td>\n",
       "      <td>Indian Subcontinent</td>\n",
       "      <td>buttermilk ,cumin ,fenugreek ,ginger garlic pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>aadu lassan keri nu athanu</td>\n",
       "      <td>TARLA_DALAL</td>\n",
       "      <td>Indian Subcontinent</td>\n",
       "      <td>asafoetida ,cayenne ,fenugreek ,ginger garlic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>aaloo kofta</td>\n",
       "      <td>TARLA_DALAL</td>\n",
       "      <td>Indian Subcontinent</td>\n",
       "      <td>butter ,cardamom ,cashew ,cayenne ,cinnamon ,c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>aaloo tamatar subzi</td>\n",
       "      <td>TARLA_DALAL</td>\n",
       "      <td>Indian Subcontinent</td>\n",
       "      <td>curry leaf ,lemon ,sunflower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Recipe ID                         Title       Source  \\\n",
       "0           0          1  5 spice vegetable fried rice  TARLA_DALAL   \n",
       "1           1          2                  aachar aaloo  TARLA_DALAL   \n",
       "2           2          3    aadu lassan keri nu athanu  TARLA_DALAL   \n",
       "3           3          4                   aaloo kofta  TARLA_DALAL   \n",
       "4           4          5           aaloo tamatar subzi  TARLA_DALAL   \n",
       "\n",
       "               Cuisine                                        Ingredients  \n",
       "0  Indian Subcontinent       capsicum ,pepper bell ,soy sauce ,sunflower   \n",
       "1  Indian Subcontinent  buttermilk ,cumin ,fenugreek ,ginger garlic pa...  \n",
       "2  Indian Subcontinent  asafoetida ,cayenne ,fenugreek ,ginger garlic ...  \n",
       "3  Indian Subcontinent  butter ,cardamom ,cashew ,cayenne ,cinnamon ,c...  \n",
       "4  Indian Subcontinent                      curry leaf ,lemon ,sunflower   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 spice vegetable fried rice'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[0,\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45772, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for delaying 5 second after each parsing to avoid getting ban\n",
    "def func(m):                  \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list to store the links\n",
    "all_links=[\"\"]*45772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the URLS\n",
    "for m in range(len(df)):\n",
    "    #s is the string you want to search on Google\n",
    "    s=df.at[m,\"Title\"]+\" \"+df.at[m,\"Source\"]  \n",
    "    s=s.replace(\"_\",\" \")\n",
    "    query = s\n",
    "    query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "    number_result = 20\n",
    "\n",
    "    ua = UserAgent()\n",
    "\n",
    "    google_url = \"https://www.google.com/search?q=\" + query + \"&num=\" + str(number_result)\n",
    "    response = requests.get(google_url,{\"User-Agent\": ua.random})           \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    #print(soup)\n",
    "    result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "   \n",
    "    links = []\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    for r in result_div:\n",
    "        # Checks if each element is present, else, raise exception\n",
    "        try:\n",
    "            link = r.find('a', href = True)\n",
    "            title = r.find('div', attrs={'class':'vvjwJb'}).get_text()\n",
    "            description = r.find('div', attrs={'class':'s3v9rd'}).get_text()\n",
    "\n",
    "            # Check to make sure everything is present before appending\n",
    "            if link != '' and title != '' and description != '': \n",
    "                links.append(link['href'])\n",
    "                titles.append(title)\n",
    "                descriptions.append(description)\n",
    "        # Next loop if one element is not present\n",
    "        except:\n",
    "            continue\n",
    "    to_remove = []\n",
    "    clean_links = []\n",
    "    for i, l in enumerate(links):\n",
    "        clean = re.search('\\/url\\?q\\=(.*)\\&sa',l)\n",
    "\n",
    "        # Anything that doesn't fit the above pattern will be removed\n",
    "        if clean is None:\n",
    "            to_remove.append(i)\n",
    "            continue\n",
    "        clean_links.append(clean.group(1))\n",
    "\n",
    "    # Remove the corresponding titles & descriptions \n",
    "    func(m)\n",
    "    if(len(clean_links)>0):\n",
    "        all_links[m]=clean_links[0]\n",
    "    else:\n",
    "        print(m)\n",
    "        break\n",
    "    if(m%10==0):\n",
    "        print(m,len(clean_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.foodnetwork.com/recipes/steamboat-natchez-sauteed-shrimp-recipe-1915206',\n",
       " 'https://www.foodnetwork.com/recipes/barmouches-picnic-coleslaw-recipe-1915125']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links[30000:30002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a 'links' column in the dataframe\n",
    "df['Links']=all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the dataframe in a csv file\n",
    "df.to_csv('lala.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
